{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Song\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "\n",
      "    Creating a shortcut link for 'en' didn't work (maybe you don't have\n",
      "    admin permissions?), but you can still load the model via its full\n",
      "    package name: nlp = spacy.load('{name}')\n",
      "    Download successful but linking failed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
    "hamlet = gutenberg.raw('shakespeare-hamlet.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', ' ', text)\n",
    "    text = re.sub('[\\[].*?[\\]]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "caesar = text_cleaner(caesar[:int(len(caesar)/10)])\n",
    "hamlet = text_cleaner(hamlet[: int(len(hamlet)/10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the cleaned novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "caesar_doc = nlp(caesar)\n",
    "hamlet_doc = nlp(hamlet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group into sentences and combine sentences into data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Actus, Primus, .)</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Scoena, Prima, .)</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Enter, Flauius, ,, Murellus, ,, and, certaine...</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Flauius, .)</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Hence, :, home, you, idle, Creatures, ,, get,...</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1\n",
       "0                                 (Actus, Primus, .)  caesar\n",
       "1                                 (Scoena, Prima, .)  caesar\n",
       "2  (Enter, Flauius, ,, Murellus, ,, and, certaine...  caesar\n",
       "3                                       (Flauius, .)  caesar\n",
       "4  (Hence, :, home, you, idle, Creatures, ,, get,...  caesar"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caesar_sents = [[sent, 'caesar'] for sent in caesar_doc.sents]\n",
    "hamlet_sents = [[sent, 'hamlet'] for sent in hamlet_doc.sents]\n",
    "\n",
    "sentences = pd.DataFrame(caesar_sents+hamlet_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    allwords = [token.lemma_ \n",
    "               for token in text\n",
    "               if not token.is_punct\n",
    "               and not token.is_stop]\n",
    "    \n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "def bow_features(sentences, common_words):\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        words = [token.lemma_ \n",
    "                for token in sentence \n",
    "                if (not token.is_punct \n",
    "                   and not token.is_stop\n",
    "                   and token.lemma_ in common_words)]\n",
    "        \n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "            \n",
    "        if i % 50 == 0:\n",
    "            print('processing row {}'.format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "caesarwords = bag_of_words(caesar_doc)\n",
    "hamletwords = bag_of_words(hamlet_doc)\n",
    "common_words = set(caesarwords + hamletwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row 0\n",
      "processing row 50\n",
      "processing row 100\n",
      "processing row 150\n",
      "processing row 200\n",
      "processing row 250\n",
      "processing row 300\n",
      "processing row 350\n",
      "processing row 400\n",
      "processing row 450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>giuing</th>\n",
       "      <th>appetite</th>\n",
       "      <th>lose</th>\n",
       "      <th>weake</th>\n",
       "      <th>channell</th>\n",
       "      <th>saide</th>\n",
       "      <th>cicero</th>\n",
       "      <th>veyl</th>\n",
       "      <th>sonne</th>\n",
       "      <th>emulate</th>\n",
       "      <th>...</th>\n",
       "      <th>disposition</th>\n",
       "      <th>palme</th>\n",
       "      <th>perceiue</th>\n",
       "      <th>helpe</th>\n",
       "      <th>obiect</th>\n",
       "      <th>chace</th>\n",
       "      <th>duty</th>\n",
       "      <th>story</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Actus, Primus, .)</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Scoena, Prima, .)</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Enter, Flauius, ,, Murellus, ,, and, certaine...</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Flauius, .)</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Hence, :, home, you, idle, Creatures, ,, get,...</td>\n",
       "      <td>caesar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  giuing appetite lose weake channell saide cicero veyl sonne emulate  ...  \\\n",
       "0      0        0    0     0        0     0      0    0     0       0  ...   \n",
       "1      0        0    0     0        0     0      0    0     0       0  ...   \n",
       "2      0        0    0     0        0     0      0    0     0       0  ...   \n",
       "3      0        0    0     0        0     0      0    0     0       0  ...   \n",
       "4      0        0    0     0        0     0      0    0     0       0  ...   \n",
       "\n",
       "  disposition palme perceiue helpe obiect chace duty story  \\\n",
       "0           0     0        0     0      0     0    0     0   \n",
       "1           0     0        0     0      0     0    0     0   \n",
       "2           0     0        0     0      0     0    0     0   \n",
       "3           0     0        0     0      0     0    0     0   \n",
       "4           0     0        0     0      0     0    0     0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0                                 (Actus, Primus, .)      caesar  \n",
       "1                                 (Scoena, Prima, .)      caesar  \n",
       "2  (Enter, Flauius, ,, Murellus, ,, and, certaine...      caesar  \n",
       "3                                       (Flauius, .)      caesar  \n",
       "4  (Hence, :, home, you, idle, Creatures, ,, get,...      caesar  \n",
       "\n",
       "[5 rows x 1248 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with features\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning models with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Y = word_counts['text_source']\n",
    "X = word_counts.drop(['text_sentence', 'text_source'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.66666667 0.74358974 0.76923077 0.79220779 0.7012987 ]\n",
      "Avg: 0.7421911421911422\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_fit = rfc.fit(X_train, y_train)\n",
    "print('Scores:', cross_val_score(rfc_fit, X_train, y_train, cv=5))\n",
    "print('Avg:', np.mean(cross_val_score(rfc_fit, X_train, y_train, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ The Tragedie of Julius Caesar by William Shakespeare 1599 ]', 'Actus Primus .', 'Enter Flauius , Murellus , and certaine Commoners ouer the Stage .', 'Flauius .']\n"
     ]
    }
   ],
   "source": [
    "caesar_paras = gutenberg.paras('shakespeare-caesar.txt')\n",
    "hamlet_paras = gutenberg.paras('shakespeare-hamlet.txt')\n",
    "joined = caesar_paras + hamlet_paras\n",
    "\n",
    "paras=[]\n",
    "for paragraph in joined:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    paras.append(' '.join(para))\n",
    "\n",
    "print(paras[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "paras_tfidf=vectorizer.fit_transform(paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = paras_tfidf\n",
    "Y_tfidf = ['caesar']*len(caesar_paras) + ['hamlet']*len(hamlet_paras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## machine learning with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.86430678 0.91445428 0.80530973 0.90855457 0.86390533]\n",
      "Avg: 0.8713061388350702\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_fit = rfc.fit(X_tfidf, Y_tfidf)\n",
    "print('Scores:', cross_val_score(rfc_fit, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg:', np.mean(cross_val_score(rfc_fit, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 84.1780795121027\n",
      "Component 0:\n",
      "[[Ham, .], [From, top, to, toe, ?], [Both, .], [My, Lord, ,, from, head, to, foote]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1.0\n",
      "[[Ham, .], [Follow, him, Friends, :, wee, ', l, heare, a, play, to, morrow, .], [Dost, thou, heare, me, old, Friend, ,, can, you, play, the, murther, of, Gonzago, ?], [Play, .], [I, my, Lord]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                1.0\n",
      "[[Ham, .], [Ha, ,, ha, :, Are, you, honest, ?], [Ophe, .], [My, Lord]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1.0\n",
      "[[Ham, .], [No, ,, no, ,, I, neuer, gaue, you, ought]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1.0\n",
      "[[Ham, .], [To, be, ,, or, not, to, be, ,, that, is, the, Question, :, Whether, ', tis, Nobler, in, the, minde, to, suffer, The, Slings, and, Arrowes, of, outragious, Fortune, ,, Or, to, take, Armes, against, a, Sea, of, troubles, ,, And, by, opposing, end, them, :, to, dye, ,, to, sleepe, No, more, ;, and, by, a, sleepe, ,, to, say, we, end, The, Heart, -, ake, ,, and, the, thousand, Naturall, shockes, That, Flesh, is, heyre, too, ?], [', Tis, a, consummation, Deuoutly, to, be, wish, ', d, .], [To, dye, to, sleepe, ,, To, sleepe, ,, perchance, to, Dreame, ;, I, ,, there, ', s, the, rub, ,, For, in, that, sleepe, of, death, ,, what, dreames, may, come, ,, When, we, haue, shuffel, ', d, off, this, mortall, coile, ,, Must, giue, vs, pawse, .], [There, ', s, the, respect, That, makes, Calamity, of, so, long, life, :, For, who, would, beare, the, Whips, and, Scornes, of, time, ,, The, Oppressors, wrong, ,, the, poore, mans, Contumely, ,, The, pangs, of, dispriz, ', d, Loue, ,, the, Lawes, delay, ,, The, insolence, of, Office, ,, and, the, Spurnes, That, patient, merit, of, the, vnworthy, takes, ,, When, he, himselfe, might, his, Quietus, make, With, a, bare, Bodkin, ?], [Who, would, these, Fardles, beare, To, grunt, and, sweat, vnder, a, weary, life, ,, But, that, the, dread, of, something, after, death, ,, The, vndiscouered, Countrey, ,, from, whose, Borne, No, Traueller, returnes, ,, Puzels, the, will, ,, And, makes, vs, rather, beare, those, illes, we, haue, ,, Then, flye, to, others, that, we, know, not, of, .], [Thus, Conscience, does, make, Cowards, of, vs, all, ,, And, thus, the, Natiue, hew, of, Resolution, Is, sicklied, o, ', re, ,, with, the, pale, cast, of, Thought, ,, And, enterprizes, of, great, pith, and, moment, ,, With, this, regard, their, Currants, turne, away, ,, And, loose, the, name, of, Action, .], [Soft, you, now, ,, The, faire, Ophelia, ?], [Nimph, ,, in, thy, Orizons, Be, all, my, sinnes, remembred]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              1.0\n",
      "[[Ham, .], [I, so, ,, God, buy, ', ye, :, Now, I, am, alone, .], [Oh, what, a, Rogue, and, Pesant, slaue, am, I, ?], [Is, it, not, monstrous, that, this, Player, heere, ,, But, in, a, Fixion, ,, in, a, dreame, of, Passion, ,, Could, force, his, soule, so, to, his, whole, conceit, ,, That, from, her, working, ,, all, his, visage, warm, ', d, ;, Teares, in, his, eyes, ,, distraction, in, ', s, Aspect, ,, A, broken, voyce, ,, and, his, whole, Function, suiting, With, Formes, ,, to, his, Conceit, ?], [And, all, for, nothing, ?], [For, Hecuba, ?], [What, ', s, Hecuba, to, him, ,, or, he, to, Hecuba, ,, That, he, should, weepe, for, her, ?], [What, would, he, doe, ,, Had, he, the, Motiue, and, the, Cue, for, passion, That, I, haue, ?], [He, would, drowne, the, Stage, with, teares, ,, And, cleaue, the, generall, eare, with, horrid, speech, :, Make, mad, the, guilty, ,, and, apale, the, free, ,, Confound, the, ignorant, ,, and, amaze, indeed, ,, The, very, faculty, of, Eyes, and, Eares, .], [Yet, I, ,, A, dull, and, muddy, -, metled, Rascall, ,, peake, Like, Iohn, a, -, dreames, ,, vnpregnant, of, my, cause, ,, And, can, say, nothing, :, No, ,, not, for, a, King, ,, Vpon, whose, property, ,, and, most, deere, life, ,, A, damn, ', d, defeate, was, made, .], [Am, I, a, Coward, ?], [Who, calles, me, Villaine, ?], [breakes, my, pate, a, -, crosse, ?], [Pluckes, off, my, Beard, ,, and, blowes, it, in, my, face, ?], [Tweakes, me, by, ', th, ', Nose, ?], [giues, me, the, Lye, i, ', th, ', Throate, ,, As, deepe, as, to, the, Lungs, ?], [Who, does, me, this, ?], [Ha, ?], [Why, I, should, take, it, :, for, it, cannot, be, ,, But, I, am, Pigeon, -, Liuer, ', d, ,, and, lacke, Gall, To, make, Oppression, bitter, ,, or, ere, this, ,, I, should, haue, fatted, all, the, Region, Kites, With, this, Slaues, Offall, ,, bloudy, :, a, Bawdy, villaine, ,, Remorselesse, ,, Treacherous, ,, Letcherous, ,, kindles, villaine, !], [Oh, Vengeance, !], [Who, ?], [What, an, Asse, am, I, ?], [I, sure, ,, this, is, most, braue, ,, That, I, ,, the, Sonne, of, the, Deere, murthered, ,, Prompted, to, my, Reuenge, by, Heauen, ,, and, Hell, ,, Must, (, like, a, Whore, ), vnpacke, my, heart, with, words, ,, And, fall, a, Cursing, like, a, very, Drab, .], [A, Scullion, ?], [Fye, vpon, ', t, :, Foh, .], [About, my, Braine, .], [I, haue, heard, ,, that, guilty, Creatures, sitting, at, a, Play, ,, Haue, by, the, very, cunning, of, the, Scoene, ,, Bene, strooke, so, to, the, soule, ,, that, presently, They, haue, proclaim, ', d, their, Malefactions, .], [For, Murther, ,, though, it, haue, no, tongue, ,, will, speake, With, most, myraculous, Organ, .], [Ile, haue, these, Players, ,, Play, something, like, the, murder, of, my, Father, ,, Before, mine, Vnkle, .], [Ile, obserue, his, lookes, ,, Ile, rent, him, to, the, quicke, :, If, he, but, blench, I, know, my, course, .], [The, Spirit, that, I, haue, seene, May, be, the, Diuell, ,, and, the, Diuel, hath, power, T, ', assume, a, pleasing, shape, ,, yea, and, perhaps, Out, of, my, Weaknesse, ,, and, my, Melancholly, ,, As, he, is, very, potent, with, such, Spirits, ,, Abuses, me, to, damne, me, .], [Ile, haue, grounds, More, Relatiue, then, this, :, The, Play, ', s, the, thing, ,, Wherein, Ile, catch, the, Conscience, of, the, King, .]]    1.0\n",
      "[[Ham, .], [Very, well, .], [Follow, that, Lord, ,, and, looke, you, mock, him, not, .], [My, good, Friends, ,, Ile, leaue, you, til, night, you, are, welcome, to, Elsonower, ?], [Rosin, .], [Good, my, Lord, .]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.0\n",
      "[[Ham, .], [Wee, ', l, ha, ', t, to, morrow, night, .], [You, could, for, a, need, study, a, speech, of, some, dosen, or, sixteene, lines, ,, which, I, would, set, downe, ,, and, insert, in, ', t, ?], [Could, ye, not, ?], [Play, .], [I, my, Lord]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         1.0\n",
      "[[Ham, .], [Gods, bodykins, man, ,, better, .], [Vse, euerie, man, after, his, desart, ,, and, who, should, scape, whipping, :, vse, them, after, your, own, Honor, and, Dignity, .], [The, lesse, they, deserue, ,, the, more, merit, is, in, your, bountie, .], [Take, them, in]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1.0\n",
      "[[Ham, .], [Or, of, a, Courtier, ,, which, could, say, ,, Good, Morrow, sweet, Lord, :, how, dost, thou, ,, good, Lord, ?], [this, might, be, my, Lord, such, a, one, ,, that, prais, ', d, my, Lord, such, a, ones, Horse, ,, when, he, meant, to, begge, it, ;, might, it, not, ?], [Hor, .], [I, ,, my, Lord]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
    "svd= TruncatedSVD(50)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=joined)\n",
    "for i in range(1):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 94.10522094216273\n",
      "Component 0:\n",
      "[[Ham, .], [From, top, to, toe, ?], [Both, .], [My, Lord, ,, from, head, to, foote]]                                                                                                                                                                                                                                                                                                                                1.0\n",
      "[[Ham, .], [I, see, a, Cherube, that, see, ', s, him, :, but, come, ,, for, England, .], [Farewell, deere, Mother]]                                                                                                                                                                                                                                                                                                 1.0\n",
      "[[Ham, .], [Very, well, .], [Follow, that, Lord, ,, and, looke, you, mock, him, not, .], [My, good, Friends, ,, Ile, leaue, you, til, night, you, are, welcome, to, Elsonower, ?], [Rosin, .], [Good, my, Lord, .]]                                                                                                                                                                                                 1.0\n",
      "[[Ham, .], [Wee, ', l, ha, ', t, to, morrow, night, .], [You, could, for, a, need, study, a, speech, of, some, dosen, or, sixteene, lines, ,, which, I, would, set, downe, ,, and, insert, in, ', t, ?], [Could, ye, not, ?], [Play, .], [I, my, Lord]]                                                                                                                                                             1.0\n",
      "[[Ham, .], [Follow, him, Friends, :, wee, ', l, heare, a, play, to, morrow, .], [Dost, thou, heare, me, old, Friend, ,, can, you, play, the, murther, of, Gonzago, ?], [Play, .], [I, my, Lord]]                                                                                                                                                                                                                    1.0\n",
      "[[Ham, .], [Gods, bodykins, man, ,, better, .], [Vse, euerie, man, after, his, desart, ,, and, who, should, scape, whipping, :, vse, them, after, your, own, Honor, and, Dignity, .], [The, lesse, they, deserue, ,, the, more, merit, is, in, your, bountie, .], [Take, them, in]]                                                                                                                                 1.0\n",
      "[[Ham, .], [', Tis, well, ,, Ile, haue, thee, speake, out, the, rest, ,, soone, .], [Good, my, Lord, ,, will, you, see, the, Players, wel, bestow, ', d, .], [Do, ye, heare, ,, let, them, be, well, vs, ', d, :, for, they, are, the, Abstracts, and, breefe, Chronicles, of, the, time, .], [After, your, death, ,, you, were, better, haue, a, bad, Epitaph, ,, then, their, ill, report, while, you, liued]]    1.0\n",
      "[[Ham, .], [The, inobled, Queene, ?], [Pol, .], [That, ', s, good, :, Inobled, Queene, is, good]]                                                                                                                                                                                                                                                                                                                   1.0\n",
      "[[Ham, .], [It, shall, to, ', th, Barbars, ,, with, your, beard, .], [Prythee, say, on, :, He, ', s, for, a, Iigge, ,, or, a, tale, of, Baudry, ,, or, hee, sleepes, .], [Say, on, ;, come, to, Hecuba]]                                                                                                                                                                                                            1.0\n",
      "[[Ham, .], [Nay, that, followes, not]]                                                                                                                                                                                                                                                                                                                                                                              1.0\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "svd= TruncatedSVD(100)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)\n",
    "\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=joined)\n",
    "for i in range(1):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
